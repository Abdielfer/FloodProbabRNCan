{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import myServices as ms\n",
    "import models as md\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, roc_auc_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute ececution time do: \n",
    "# with timeit():\n",
    "#     # your code, e.g., \n",
    "class timeit(): \n",
    "    from datetime import datetime\n",
    "    def __enter__(self):\n",
    "        self.tic = self.datetime.now()\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print('runtime: {}'.format(self.datetime.now() - self.tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and manipulating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning basin1DataSet \n",
    "dataSetPath = 'datasets/datasetBasin1.csv'\n",
    "basinDataSet = pd.read_csv(dataSetPath, index_col = None)\n",
    "# basin1Light = pd.read_csv('datasetBasin1_NoDataFree.csv', index_col = None)\n",
    "# print(basinDataSet.info())\n",
    "# basinDataSet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = ['percentage','DLSOL5R200', 'DLSOL4R150', 'DLSOL5R150']\n",
    "for col in colNames: \n",
    "    basinDataSet[col].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.dropna(subset=['slope'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.drop(['fid'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOrmalize Flow Accumulation\n",
    "basinDataSet['FAcc'] = (basinDataSet['FAcc']- basinDataSet['FAcc'].min())/(basinDataSet['FAcc'].max()-basinDataSet['FAcc'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replacing QGIS NoData value(-9999) with 0 \n",
    "repalcer  = basinDataSet['FAProx_01'].to_numpy()\n",
    "basinDataSet['FAProx_01'] = [0 if repalcer[j] == -9999 else repalcer[j] for j in range(len(repalcer))]                                                                                                                         \n",
    "                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform a column datatype\n",
    "repalcer  = basinDataSet['percentage'].to_numpy().astype('int')\n",
    "basinDataSet.loc[:,'percentage'] = repalcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.to_csv('datasets/basin1_FirstFeatureSet_Clean.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DS.head(5)\n",
    "s = {}\n",
    "s['Datas'] = ds\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportional Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X,Y = ms.importDataSet('datasets/basin1_FirstFeatureSet_Clean.csv', 'percentage')\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=50)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = Y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = Y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describing training set\n",
    "print(len(X_train['elevation']), len(y_train) )\n",
    "trainCount = Counter(y_train)\n",
    "print(trainCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####    Creating training set     #####\n",
    "X_train.loc[:,'percentage'] = y_train\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing coordinates from training set\n",
    "X_train.drop(['x_coord','y_coord'], axis =1, inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('datasets/basin1_FirstFeatureSet_Clean_Training.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####. Creating Test set\n",
    "print(X_test.head())\n",
    "X_test.loc[:,'percentage'] = y_test\n",
    "print(X_test.head())\n",
    "print(X_test.info())\n",
    "testCount = Counter(X_test['percentage'])\n",
    "print(f\"testCount:  {testCount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('datasets/basin1_FirstFeatureSet_Clean_Test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This proportions are the reason why a sample_weight of 0.01 for the majority class give best results for regression\n",
    "totalTrain = sum([trainCount[0], trainCount[1], trainCount[5]]) \n",
    "totalValidation = sum([testCount[0], testCount[1], testCount[5]])\n",
    "print(f\"total Train samples: {totalTrain},  total Validation samples: {totalValidation}\")\n",
    "print(\"Summary of traning and test dataset class balance\")\n",
    "print(f\"Training Set:\", '\\n', \"Class 0: %.3f\" %(trainCount[0]/totalTrain), \" Class 1: %.4f\" %(trainCount[1]/totalTrain), \"Class 5: %.4f\"%(trainCount[5]/totalTrain))\n",
    "print(\"Testing Set:\", '\\n', \"Class 0: %.3f\" %(testCount[0]/totalValidation),\" Class 1: %.4f\" %(testCount[1]/totalValidation),  \"Class 5: %.4f\"%(testCount[5]/totalValidation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ms.loadModel('./outputs/2022-08-05/00-35-58/2208050035.pkl')\n",
    "dataSetToSave = ms.makePredictionToImportAsSHP(csvName, model, X, Y, 'percentage')\n",
    "print(dataSetToSave.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining dataSets to build AllVsOne_training and OneVsAll_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat datasets\n",
    "sourceFileForDatasets = 'datasets/'\n",
    "allDataSetsNames = ['basin1Light_Clean.csv', 'basin2_CleanDataSet.csv', 'basin3_CleanDataSet_copy.csv','basin4_CleanDataSet.csv','basin5_CleanDataSet.csv']\n",
    "# OneVsAllDataSetName = 'basin1Light_Clean.csv'\n",
    "\n",
    "for datasetForTest in allDataSetsNames:\n",
    "    filename, file_extension = os.path.splitext(datasetForTest)\n",
    "    newListOfNames = [s for s in allDataSetsNames if s != datasetForTest]\n",
    "    allDataSetsFileName = 'allVs_'+ filename +'_Training'\n",
    "    DFToConcatAll = pd.DataFrame()\n",
    "#     DFToConcatAll = pd.read_csv((sourceFileForDatasets+datasetForTest), index_col = None)\n",
    "#     print(DFToConcatAll.head())\n",
    "    for datasets in newListOfNames:\n",
    "        DFToConcatAll = pd.concat([DFToConcatAll, pd.read_csv((sourceFileForDatasets+datasets), index_col = None)])\n",
    "    nameToSafe = sourceFileForDatasets+allDataSetsFileName+file_extension\n",
    "    DFToConcatAll.drop(['x_coord','y_coord'], axis =1, inplace=True)\n",
    "    DFToConcatAll.to_csv(nameToSafe, index=None)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing datasets for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning datasets: Removing not usefull variables from All_VS_ONE \n",
    "readPath = 'datasets/'\n",
    "destiationPath = 'datasets/dataset4MLP/'\n",
    "datasetNamelist = ['allVs_basin1Light_Clean_Training.csv', 'allVs_basin2_CleanDataSet_Training.csv','allVs_basin3_CleanDataSet_copy_Training.csv',\n",
    "'allVs_basin4_CleanDataSet_Training.csv','allVs_basin5_CleanDataSet_Training.csv','basin1Light_Clean_VsAll_Test.csv',\n",
    "'basin2_CleanDataSet_VsAll_Test.csv','basin3_CleanDataSet_copy_VsAll_Test.csv', 'basin4_CleanDataSet_VsAll_Test.csv', \n",
    "'basin5_CleanDataSet_VsAll_Test.csv']\n",
    "featuresToDelete = ['TPI','TWI']\n",
    "for i in datasetNamelist:\n",
    "    path = readPath + i \n",
    "    basinDataSet = pd.read_csv(path, index_col = None)\n",
    "    basinDataSet.drop(featuresToDelete, axis=1, inplace=True)\n",
    "    savePath = destiationPath + 'MLP_'+i\n",
    "    basinDataSet.to_csv(savePath, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###. Build dataset subset for MLP test (Only first 150K samples)\n",
    "readPath = 'datasets/dataset4MLP/'\n",
    "datasetNamelist = ['MLP_allVs_basin1Light_Clean_Training.csv','MLP_basin1Light_Clean_VsAll_Test.csv']\n",
    "for i in datasetNamelist:\n",
    "    path = readPath + i \n",
    "    basinDataSet = pd.read_csv(path, index_col = None)\n",
    "    Y = np.array(basinDataSet['percentage'])\n",
    "    count,_ = md.listClassCountPercent(Y)\n",
    "    basinDataSet.drop(basinDataSet.loc[150000:count].index,axis=0,inplace=True)\n",
    "    savePath = readPath + 'reduced_'+i\n",
    "    basinDataSet.to_csv(savePath, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exploring datasets\n",
    "dataset = ['reduced_MLP_allVs_basin1Light_Clean_Training.csv','reduced_MLP_basin1Light_Clean_VsAll_Test.csv']\n",
    "for i in dataset:\n",
    "    path = readPath + i \n",
    "    print(path)\n",
    "    basinDataSet = pd.read_csv(path, index_col = None)\n",
    "    print(basinDataSet.head())\n",
    "    Y = np.array(basinDataSet['percentage'])\n",
    "    print(md.listClassCountPercent(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "def training(model, x_train,y_train, x_valid, y_valid, epochs, threshold):\n",
    "    for i in epochs:\n",
    "        model.fit(x_train,y_train)\n",
    "        if i == threshold:\n",
    "            md.computeClassificationMetrics(mlpClassifier,X,y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/dataset4MLP/MLP_allVs_basin1Light_Clean_Training.csv\n",
      "percentage\n",
      "   DLSOL4R150  DLSOL5R150  DLSOL5R200  FAProx_01  FAProx_025     FAcc  \\\n",
      "0         0.0         0.0         0.0  725.43091   174.75125  0.00000   \n",
      "1         0.0         0.0         0.0  709.11920   171.02631  0.00000   \n",
      "2         0.0         0.0         0.0  737.05499   176.23280  0.00001   \n",
      "3         0.0         0.0         0.0  721.00623   172.53986  0.00000   \n",
      "4         0.0         0.0         0.0  749.03271   177.79201  0.00000   \n",
      "\n",
      "   visibility    slope  elevation  \n",
      "0     0.02455  1.97503  174.32889  \n",
      "1     0.02849  7.28373  173.66133  \n",
      "2     0.02651  3.28983  173.39836  \n",
      "3     0.02117  0.36284  172.95361  \n",
      "4     0.00134  0.19720  172.93945  \n",
      "Train balance\n",
      "(1370466, {0: 'Class_count: 1327657  for  0.9688  percent', 1: 'Class_count: 8130  for  0.0059  percent', 5: 'Class_count: 34679  for  0.0253  percent'})\n",
      "Iteration 1, loss = 0.12201837\n",
      "Validation score: 0.969737\n",
      "Iteration 2, loss = 0.09152146\n",
      "Validation score: 0.970849\n",
      "Iteration 3, loss = 0.08845378\n",
      "Validation score: 0.971397\n",
      "Iteration 4, loss = 0.08631045\n",
      "Validation score: 0.972115\n",
      "Iteration 5, loss = 0.08521418\n",
      "Validation score: 0.972137\n",
      "Iteration 6, loss = 0.08426574\n",
      "Validation score: 0.972094\n",
      "Iteration 7, loss = 0.08336351\n",
      "Validation score: 0.972152\n",
      "Iteration 8, loss = 0.08285600\n",
      "Validation score: 0.972750\n",
      "Iteration 9, loss = 0.08231712\n",
      "Validation score: 0.972345\n",
      "Iteration 10, loss = 0.08197198\n",
      "Validation score: 0.972630\n",
      "Iteration 11, loss = 0.08163659\n",
      "Validation score: 0.972849\n",
      "Iteration 12, loss = 0.08121033\n",
      "Validation score: 0.973633\n",
      "Iteration 13, loss = 0.08085808\n",
      "Validation score: 0.973232\n",
      "Iteration 14, loss = 0.08070981\n",
      "Validation score: 0.972849\n",
      "Iteration 15, loss = 0.08052828\n",
      "Validation score: 0.973443\n",
      "Iteration 16, loss = 0.08045832\n",
      "Validation score: 0.973684\n",
      "Iteration 17, loss = 0.08020188\n",
      "Validation score: 0.973535\n",
      "Iteration 18, loss = 0.08015779\n",
      "Validation score: 0.973640\n",
      "Iteration 19, loss = 0.07998944\n",
      "Validation score: 0.973166\n",
      "Iteration 20, loss = 0.07986515\n",
      "Validation score: 0.973845\n",
      "Iteration 21, loss = 0.07971971\n",
      "Validation score: 0.973082\n",
      "Iteration 22, loss = 0.07954274\n",
      "Validation score: 0.973702\n",
      "Iteration 23, loss = 0.07961365\n",
      "Validation score: 0.973823\n",
      "Iteration 24, loss = 0.07943647\n",
      "Validation score: 0.973137\n",
      "Iteration 25, loss = 0.07942142\n",
      "Validation score: 0.973327\n",
      "Iteration 26, loss = 0.07929953\n",
      "Validation score: 0.974363\n",
      "Iteration 27, loss = 0.07927111\n",
      "Validation score: 0.973881\n",
      "Iteration 28, loss = 0.07924877\n",
      "Validation score: 0.973790\n",
      "Iteration 29, loss = 0.07907975\n",
      "Validation score: 0.974005\n",
      "Iteration 30, loss = 0.07901701\n",
      "Validation score: 0.974191\n",
      "Iteration 31, loss = 0.07898067\n",
      "Validation score: 0.974173\n",
      "Iteration 32, loss = 0.07894277\n",
      "Validation score: 0.974414\n",
      "Iteration 33, loss = 0.07888781\n",
      "Validation score: 0.974279\n",
      "Iteration 34, loss = 0.07884430\n",
      "Validation score: 0.973826\n",
      "Iteration 35, loss = 0.07878320\n",
      "Validation score: 0.974604\n",
      "Iteration 36, loss = 0.07873367\n",
      "Validation score: 0.973743\n",
      "Iteration 37, loss = 0.07862592\n",
      "Validation score: 0.974432\n",
      "Iteration 38, loss = 0.07858335\n",
      "Validation score: 0.974290\n",
      "Iteration 39, loss = 0.07849648\n",
      "Validation score: 0.974166\n",
      "Iteration 40, loss = 0.07833457\n",
      "Validation score: 0.973633\n",
      "Iteration 41, loss = 0.07839078\n",
      "Validation score: 0.973903\n",
      "Iteration 42, loss = 0.07840080\n",
      "Validation score: 0.974823\n",
      "Iteration 43, loss = 0.07836778\n",
      "Validation score: 0.974487\n",
      "Iteration 44, loss = 0.07830842\n",
      "Validation score: 0.974399\n",
      "Iteration 45, loss = 0.07823799\n",
      "Validation score: 0.974593\n",
      "Iteration 46, loss = 0.07809602\n",
      "Validation score: 0.973432\n",
      "Iteration 47, loss = 0.07808534\n",
      "Validation score: 0.974706\n",
      "Iteration 48, loss = 0.07795354\n",
      "Validation score: 0.974472\n",
      "Iteration 49, loss = 0.07792367\n",
      "Validation score: 0.974596\n",
      "Iteration 50, loss = 0.07802752\n",
      "Validation score: 0.974483\n",
      "Iteration 51, loss = 0.07799223\n",
      "Validation score: 0.974512\n",
      "Iteration 52, loss = 0.07788511\n",
      "Validation score: 0.974516\n"
     ]
    }
   ],
   "source": [
    "####.  Training TEST\n",
    "\n",
    "readPath = 'datasets/dataset4MLP/'\n",
    "trainingPath = readPath + 'MLP_allVs_basin1Light_Clean_Training.csv'\n",
    "# dataset = pd.read_csv(trainingPath, index_col = None)\n",
    "args = {'eStop': True}\n",
    "mlpc = md.implementingMLPCalssifier(trainingPath,'percentage',args)\n",
    "mlpc.fitMLPClassifier()\n",
    "mlpc.plotLossBehaviour()\n",
    "\n",
    "mlpClassifier = mlpc.getMLPClassifier()\n",
    "\n",
    "#Validating un unseen dataset\n",
    "validation = readPath + 'MLP_basin1Light_Clean_VsAll_Test.csv'\n",
    "x_val,y_val = ms.importDataSet(validation, 'percentage')\n",
    "prediction = ms.makePredictionToImportAsSHP(mlpClassifier, x_val, y_val, 'percentage')\n",
    "\n",
    "## Compute metrics\n",
    "X = x_val.copy()\n",
    "X.drop(['percentage','x_coord','y_coord','prediction'], axis=1, inplace=True)\n",
    "metrics = md.computeClassificationMetrics(mlpClassifier,X,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hidden_layer_sizes=[100,100] earlyStop True\n",
    "ROC_AUC one_vs_all:  {0: 0.6228742547616204, 1: 0.4999938829459356, 5: 0.6399651931990683}\n",
    "'''\n",
    "'''\n",
    "hidden_layer_sizes=[100,100] earlyStop False, Epochs = 45  IT´s NOT Better!!\n",
    "'''\n",
    "'''\n",
    "hidden_layer_sizes=[1000,1000] earlyStop True\n",
    "'''\n",
    "'''\n",
    "hidden_layer_sizes=(16,32,64,32,16), earlyStop True\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print(mlpc.get_logsDic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(('outputs/'+ 'MLP_basin1Light_firstResult200.csv'),index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controled sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv('datasets/basin2 _Training.csv', index_col = None)\n",
    "print(DS.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DS.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(DS['FAProx_01']) # , , DS['elevation'], DS['disToRiv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resampling appliying class selection by rule:\n",
    "\n",
    "# RULE1: Select point at a distance to river less than 300m. \n",
    "\n",
    "# # newDS = pseudoClassCreation(DS, \"distanceToRiver\", 300, 2)\n",
    "def pseudoClassCreation(dataset, conditionVariable, threshold, pseudoClass, targetClassName):\n",
    "    '''\n",
    "    Replace <targetClass> by  <pseudoClass> where <conditionVariable >= threshold>. \n",
    "    Return:\n",
    "      dataset with new classes group. \n",
    "    '''\n",
    "    datsetReclassified = dataset.copy()\n",
    "    actualTarget = (np.array(dataset[targetClassName])).ravel()\n",
    "    conditionVar = (np.array(dataset[conditionVariable])).ravel()\n",
    "    datsetReclassified[targetClassName] = [ pseudoClass if conditionVar[j] >= threshold \n",
    "                                           else actualTarget[j]\n",
    "                                           for j in range(len(actualTarget))]\n",
    "    print(Counter(datsetReclassified[targetClassName]))\n",
    "    return  datsetReclassified\n",
    "\n",
    "def revertPseudoClassCreation(dataset, originalClass, pseudoClass, targetClassName):\n",
    "    '''\n",
    "    Restablich  <targetClass> with <originalClass> where <targetClassName == pseudoClass>. \n",
    "    Return:\n",
    "      dataset with original classes group. \n",
    "    '''\n",
    "    datsetReclassified = dataset.copy()\n",
    "    actualTarget = (np.array(dataset[targetClassName])).ravel()\n",
    "    datsetReclassified[targetClassName] = [ originalClass if actualTarget[j] == pseudoClass\n",
    "                                           else actualTarget[j]\n",
    "                                           for j in range(len(actualTarget))]\n",
    "    print(Counter(datsetReclassified[targetClassName]))\n",
    "    return  datsetReclassified\n",
    "\n",
    "\n",
    "print(Counter(X_train['percentage']))\n",
    "newDS = pseudoClassCreation(X_train, 'disToRiv', 200, 2, 'percentage')\n",
    "y = newDS['percentage']\n",
    "newDS.drop(['percentage'], axis=1, inplace = True)\n",
    "x_res,y_res = ms.randomUndersampling(newDS, y, )\n",
    "x_res['percentage'] = y_res\n",
    "# newDatase = revertPseudoClassCreation(x_res, 0, 2, 'percentage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res.to_csv('basin1ControlClass0Sampling4Class_ToSHP.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import dataset to describe\n",
    "DS= pd.read_csv('datasets/basin4_Training.csv', index_col=None)\n",
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.drop(['x_coord','y_coord'], axis = 1, inplace=True)\n",
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAcc vs Labels\n",
    "targets = DS['percentage']\n",
    "FAcc = original['FAcc']\n",
    "FAcc_norm = DS['FAcc_norm']\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13,4), sharey=True)\n",
    "fig.text(-0.02, 0.5, 'labels', va='center', rotation='vertical')\n",
    "fig.text(0.5, 1, 'Flow accumulation vs labels distribution', ha ='center')\n",
    "axs[0].scatter(FAcc,targets)\n",
    "# axs[0].set_title(\"Facc\")\n",
    "axs[0].set(xlabel='a) Flow Accumulation')\n",
    "axs[1].scatter(FAcc_norm,targets)\n",
    "# axs[1].set_title(\"FAcc_norm\")\n",
    "axs[1].set(xlabel='b) Flow Accumulation estandardized')\n",
    "plt.rcParams['font.size'] = '20'\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Plot all features vs labels\n",
    "# 'disToRiv', 'TWI', 'TPI', 'slope', 'elevation',\n",
    "\n",
    "targets = DS['percentage']\n",
    "# targets = np.where(targets == 5,2,targets)\n",
    "\n",
    "E = DS['elevation'] \n",
    "slope = DS['slope']\n",
    "FAcc = DS['FAcc']\n",
    "TWI = DS['TWI']\n",
    "TPI = DS['TPI']\n",
    "DLSOL4R150 = DS['LDSOL4R150']\n",
    "DLSOL5R150 = DS['LDSOL5R150']\n",
    "DLSOL5R200 = DS['LDSOL5R200']\n",
    "FAProx_01 = DS['FAProx_01']\n",
    "FAProx_025 = DS['FAProx_025']\n",
    "visibility = DS['visibility']\n",
    "\n",
    "fig, axs = plt.subplots(4,3, figsize=(13, 8), sharey=True)\n",
    "fig.supylabel('Labels')\n",
    "plt.rcParams['font.size'] = '15'\n",
    "plt.yticks([0,1,5])\n",
    "\n",
    "'''\n",
    "E = DS['elevation'] \n",
    "slope = DS['slope']\n",
    "FAcc = DS['FAcc']\n",
    "TWI = DS['TWI']\n",
    "'''\n",
    "axs[0, 0].scatter(E,targets)\n",
    "axs[0, 0].set_title(\"Elevation\")\n",
    "axs[1, 0].scatter(slope,targets)\n",
    "axs[1, 0].set_title(\"Slope\")\n",
    "axs[2, 0].scatter(FAcc,targets)\n",
    "axs[2, 0].set_title(\"Flow accumulation\")\n",
    "axs[3, 0].scatter(TWI,targets)\n",
    "axs[3, 0].set_title(\"TWI\")\n",
    "\n",
    "'''\n",
    "TPI = DS['TPI']\n",
    "DLSOL4R150 = DS['DLSOL4R150']\n",
    "DLSOL5R150 = DS['DLSOL5R150']\n",
    "DLSOL5R200 = DS['DLSOL5R200']\n",
    "'''\n",
    "axs[0, 1].scatter(TPI,targets)\n",
    "axs[0, 1].set_title('TPI')\n",
    "axs[1, 1].scatter(DLSOL4R150,targets)\n",
    "axs[1, 1].set_title(\"DLSOL4R150\")\n",
    "axs[2, 1].scatter(DLSOL5R150,targets)\n",
    "axs[2, 1].set_title(\"DLSOL5R150\")\n",
    "axs[3, 1].scatter(DLSOL5R200,targets)\n",
    "axs[3, 1].set_title(\"DLSOL5R200\")\n",
    "\n",
    "'''\n",
    "FAProx_01 = DS['FAProx_01']\n",
    "FAProx_025 = DS['FAProx_025']\n",
    "visibility = DS['visibility']\n",
    "'''\n",
    "axs[0, 2].scatter(FAProx_01,targets)\n",
    "axs[0, 2].set_title('FAProx_01')\n",
    "axs[1, 2].scatter(FAProx_025,targets)\n",
    "axs[1, 2].set_title(\"FAProx_025\")\n",
    "axs[2, 2].scatter(visibility,targets)\n",
    "axs[2, 2].set_title(\"Visibility\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DS.head())\n",
    "#  Return a dataset with the rows corresponding to the index where condition in DS.columName is valid. \n",
    "dsArray = DS[DS.percentage != 0] \n",
    "print(dsArray.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.pairplot(DS, hue = 'percentage', diag_kind = 'kde', \n",
    "             plot_kws = {'alpha': 0.8, 's': 100},\n",
    "             height = 4, corner=True, palette = \"Set2\")# vars = ['life_exp', 'log_pop', 'log_gdp_per_cap'],\n",
    "\n",
    "# sns.pairplot(DS, hue=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Covariance Matrix\n",
    "sns.set(font_scale=0.7)\n",
    "matrix = DS.corr().round(2)\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.set_figsize=(25,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(criterion='entropy', random_state = 50)\n",
    "x_train,y_train = ms.importDataSet('basin1Train.csv', 'percentage')\n",
    "classifier = OneVsRestClassifier(estimator).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ms.loadModel('./outputs/2022-08-05/11-01-57/2208051101.pkl')\n",
    "x_test,y_test = ms.importDataSet('basin1Test.csv', 'percentage')\n",
    "\n",
    "x_test = ms.removeCoordinatesFromDataSet(x_test)\n",
    "\n",
    "# y_prob = classifier.predict_proba(x_test)\n",
    "#print(np.unique(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.plot_ROC_AUC_OneVsRest(classifier, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,y_test = ms.importDataSet('./bestModels/Classifier/10-18-08/2208051018prediction_basin1Test.csv', 'prediction')\n",
    "unique, count = np.unique(y_test, return_counts=True)\n",
    "total = count.sum()\n",
    "print(total)\n",
    "percent = np.round(np.zeros_like(unique).astype('float16'),3)\n",
    "print('values, counts , percent')\n",
    "for i in range(len(unique)):    \n",
    "   percent[i] = (count[i]/total)*100\n",
    "   print(unique[i],\"\\t\", count[i], percent[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c444c068df4da933f83035bc75b2ed5aea8e7fb8bc113357e2f14ee7cca6a8fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
