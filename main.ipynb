{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import myServices as ms\n",
    "import models as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, roc_auc_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute ececution time do: \n",
    "# with timeit():\n",
    "#     # your code, e.g., \n",
    "class timeit(): \n",
    "    from datetime import datetime\n",
    "    def __enter__(self):\n",
    "        self.tic = self.datetime.now()\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print('runtime: {}'.format(self.datetime.now() - self.tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage        0\n",
      "disToRiv          0\n",
      "TWI               1\n",
      "TPI               0\n",
      "FAcc              0\n",
      "slope         14442\n",
      "elevation         0\n",
      "x_coord           0\n",
      "y_coord           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>disToRiv</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TPI</th>\n",
       "      <th>FAcc</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493979e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.150033e-02</td>\n",
       "      <td>2.097987e+02</td>\n",
       "      <td>9.478135e+00</td>\n",
       "      <td>1.100693e-04</td>\n",
       "      <td>4.330615e+04</td>\n",
       "      <td>4.821367e+00</td>\n",
       "      <td>1.455343e+02</td>\n",
       "      <td>3.650845e+05</td>\n",
       "      <td>5.264240e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.592287e-01</td>\n",
       "      <td>1.727702e+02</td>\n",
       "      <td>4.079174e+00</td>\n",
       "      <td>1.950585e-01</td>\n",
       "      <td>1.029387e+06</td>\n",
       "      <td>4.994698e+00</td>\n",
       "      <td>4.576501e+01</td>\n",
       "      <td>3.175800e+03</td>\n",
       "      <td>1.830620e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.252120e+00</td>\n",
       "      <td>-7.461320e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>4.700000e-04</td>\n",
       "      <td>-3.808000e-02</td>\n",
       "      <td>3.586730e+05</td>\n",
       "      <td>5.260213e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.424622e+01</td>\n",
       "      <td>5.551585e+00</td>\n",
       "      <td>-6.195000e-02</td>\n",
       "      <td>8.772391e+01</td>\n",
       "      <td>1.600760e+00</td>\n",
       "      <td>1.159088e+02</td>\n",
       "      <td>3.623130e+05</td>\n",
       "      <td>5.262718e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.691892e+02</td>\n",
       "      <td>1.025464e+01</td>\n",
       "      <td>-2.100000e-04</td>\n",
       "      <td>2.851745e+02</td>\n",
       "      <td>3.192175e+00</td>\n",
       "      <td>1.483494e+02</td>\n",
       "      <td>3.650780e+05</td>\n",
       "      <td>5.264348e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.030264e+02</td>\n",
       "      <td>1.288554e+01</td>\n",
       "      <td>6.131000e-02</td>\n",
       "      <td>1.254889e+03</td>\n",
       "      <td>6.192805e+00</td>\n",
       "      <td>1.800543e+02</td>\n",
       "      <td>3.676380e+05</td>\n",
       "      <td>5.265788e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.355775e+03</td>\n",
       "      <td>2.486353e+01</td>\n",
       "      <td>6.706970e+00</td>\n",
       "      <td>6.282632e+07</td>\n",
       "      <td>7.002943e+01</td>\n",
       "      <td>2.605691e+02</td>\n",
       "      <td>3.721230e+05</td>\n",
       "      <td>5.267983e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         percentage      disToRiv           TWI           TPI          FAcc  \\\n",
       "count  2.493980e+06  2.493980e+06  2.493979e+06  2.493980e+06  2.493980e+06   \n",
       "mean   9.150033e-02  2.097987e+02  9.478135e+00  1.100693e-04  4.330615e+04   \n",
       "std    6.592287e-01  1.727702e+02  4.079174e+00  1.950585e-01  1.029387e+06   \n",
       "min    0.000000e+00  0.000000e+00 -9.252120e+00 -7.461320e+00  2.500000e+01   \n",
       "25%    0.000000e+00  7.424622e+01  5.551585e+00 -6.195000e-02  8.772391e+01   \n",
       "50%    0.000000e+00  1.691892e+02  1.025464e+01 -2.100000e-04  2.851745e+02   \n",
       "75%    0.000000e+00  3.030264e+02  1.288554e+01  6.131000e-02  1.254889e+03   \n",
       "max    5.000000e+00  1.355775e+03  2.486353e+01  6.706970e+00  6.282632e+07   \n",
       "\n",
       "              slope     elevation       x_coord       y_coord  \n",
       "count  2.479538e+06  2.493980e+06  2.493980e+06  2.493980e+06  \n",
       "mean   4.821367e+00  1.455343e+02  3.650845e+05  5.264240e+06  \n",
       "std    4.994698e+00  4.576501e+01  3.175800e+03  1.830620e+03  \n",
       "min    4.700000e-04 -3.808000e-02  3.586730e+05  5.260213e+06  \n",
       "25%    1.600760e+00  1.159088e+02  3.623130e+05  5.262718e+06  \n",
       "50%    3.192175e+00  1.483494e+02  3.650780e+05  5.264348e+06  \n",
       "75%    6.192805e+00  1.800543e+02  3.676380e+05  5.265788e+06  \n",
       "max    7.002943e+01  2.605691e+02  3.721230e+05  5.267983e+06  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataSetPath = 'datasets/datasetBasin1.csv'\n",
    "basinDataSet = pd.read_csv(dataSetPath, index_col = None)\n",
    "print(basinDataSet.isna().sum())\n",
    "basinDataSet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and manipulating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning basin1DataSet \n",
    "dataSetPath = 'datasets/datasetBasin1.csv'\n",
    "basinDataSet = pd.read_csv(dataSetPath, index_col = None)\n",
    "# basin1Light = pd.read_csv('datasetBasin1_NoDataFree.csv', index_col = None)\n",
    "# print(basinDataSet.info())\n",
    "# basinDataSet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = ['percentage','DLSOL5R200', 'DLSOL4R150', 'DLSOL5R150']\n",
    "for col in colNames: \n",
    "    basinDataSet[col].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.dropna(subset=['slope'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.drop(['fid'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage    0\n",
       "disToRiv      0\n",
       "TWI           0\n",
       "TPI           0\n",
       "FAcc          0\n",
       "slope         0\n",
       "elevation     0\n",
       "x_coord       0\n",
       "y_coord       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basinDataSet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOrmalize Flow Accumulation\n",
    "basinDataSet['FAcc'] = (basinDataSet['FAcc']- basinDataSet['FAcc'].min())/(basinDataSet['FAcc'].max()-basinDataSet['FAcc'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replacing QGIS NoData value(-9999) with 0 \n",
    "repalcer  = basinDataSet['FAProx_01'].to_numpy()\n",
    "basinDataSet['FAProx_01'] = [0 if repalcer[j] == -9999 else repalcer[j] for j in range(len(repalcer))]                                                                                                                         \n",
    "                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform a column datatype\n",
    "repalcer  = basinDataSet['percentage'].to_numpy().astype('int')\n",
    "basinDataSet.loc[:,'percentage'] = repalcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>disToRiv</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TPI</th>\n",
       "      <th>FAcc</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.201795e-02</td>\n",
       "      <td>2.084064e+02</td>\n",
       "      <td>9.483515e+00</td>\n",
       "      <td>-3.328848e-04</td>\n",
       "      <td>4.352760e+04</td>\n",
       "      <td>4.821367e+00</td>\n",
       "      <td>1.453463e+02</td>\n",
       "      <td>3.650828e+05</td>\n",
       "      <td>5.264239e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.610626e-01</td>\n",
       "      <td>1.713850e+02</td>\n",
       "      <td>4.081659e+00</td>\n",
       "      <td>1.949152e-01</td>\n",
       "      <td>1.031605e+06</td>\n",
       "      <td>4.994698e+00</td>\n",
       "      <td>4.569706e+01</td>\n",
       "      <td>3.169308e+03</td>\n",
       "      <td>1.824893e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.252120e+00</td>\n",
       "      <td>-7.461320e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>4.700000e-04</td>\n",
       "      <td>-3.685000e-02</td>\n",
       "      <td>3.586780e+05</td>\n",
       "      <td>5.260218e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.382411e+01</td>\n",
       "      <td>5.553190e+00</td>\n",
       "      <td>-6.226000e-02</td>\n",
       "      <td>8.892947e+01</td>\n",
       "      <td>1.600760e+00</td>\n",
       "      <td>1.157656e+02</td>\n",
       "      <td>3.623130e+05</td>\n",
       "      <td>5.262723e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.677051e+02</td>\n",
       "      <td>1.025636e+01</td>\n",
       "      <td>-2.700000e-04</td>\n",
       "      <td>2.881975e+02</td>\n",
       "      <td>3.192175e+00</td>\n",
       "      <td>1.481632e+02</td>\n",
       "      <td>3.650730e+05</td>\n",
       "      <td>5.264348e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.010399e+02</td>\n",
       "      <td>1.289330e+01</td>\n",
       "      <td>6.091000e-02</td>\n",
       "      <td>1.265309e+03</td>\n",
       "      <td>6.192805e+00</td>\n",
       "      <td>1.797259e+02</td>\n",
       "      <td>3.676280e+05</td>\n",
       "      <td>5.265783e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.349713e+03</td>\n",
       "      <td>2.486353e+01</td>\n",
       "      <td>6.706970e+00</td>\n",
       "      <td>6.282450e+07</td>\n",
       "      <td>7.002943e+01</td>\n",
       "      <td>2.605691e+02</td>\n",
       "      <td>3.721180e+05</td>\n",
       "      <td>5.267978e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         percentage      disToRiv           TWI           TPI          FAcc  \\\n",
       "count  2.479538e+06  2.479538e+06  2.479538e+06  2.479538e+06  2.479538e+06   \n",
       "mean   9.201795e-02  2.084064e+02  9.483515e+00 -3.328848e-04  4.352760e+04   \n",
       "std    6.610626e-01  1.713850e+02  4.081659e+00  1.949152e-01  1.031605e+06   \n",
       "min    0.000000e+00  0.000000e+00 -9.252120e+00 -7.461320e+00  2.500000e+01   \n",
       "25%    0.000000e+00  7.382411e+01  5.553190e+00 -6.226000e-02  8.892947e+01   \n",
       "50%    0.000000e+00  1.677051e+02  1.025636e+01 -2.700000e-04  2.881975e+02   \n",
       "75%    0.000000e+00  3.010399e+02  1.289330e+01  6.091000e-02  1.265309e+03   \n",
       "max    5.000000e+00  1.349713e+03  2.486353e+01  6.706970e+00  6.282450e+07   \n",
       "\n",
       "              slope     elevation       x_coord       y_coord  \n",
       "count  2.479538e+06  2.479538e+06  2.479538e+06  2.479538e+06  \n",
       "mean   4.821367e+00  1.453463e+02  3.650828e+05  5.264239e+06  \n",
       "std    4.994698e+00  4.569706e+01  3.169308e+03  1.824893e+03  \n",
       "min    4.700000e-04 -3.685000e-02  3.586780e+05  5.260218e+06  \n",
       "25%    1.600760e+00  1.157656e+02  3.623130e+05  5.262723e+06  \n",
       "50%    3.192175e+00  1.481632e+02  3.650730e+05  5.264348e+06  \n",
       "75%    6.192805e+00  1.797259e+02  3.676280e+05  5.265783e+06  \n",
       "max    7.002943e+01  2.605691e+02  3.721180e+05  5.267978e+06  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basinDataSet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinDataSet.to_csv('datasets/basin1_FirstFeatureSet_Clean.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DS.head(5)\n",
    "s = {}\n",
    "s['Datas'] = ds\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportional Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1983630 TEST: 495908\n"
     ]
    }
   ],
   "source": [
    "## Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X,Y = ms.importDataSet('datasets/basin1_FirstFeatureSet_Clean.csv', 'percentage')\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=50)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = Y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = Y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983630 1983630\n",
      "Counter({0: 1941324, 5: 35056, 1: 7250})\n"
     ]
    }
   ],
   "source": [
    "## Describing training set\n",
    "print(len(X_train['elevation']), len(y_train) )\n",
    "trainCount = Counter(y_train)\n",
    "print(trainCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/cqkwnnps0f1_35_bccj0y8q80000gn/T/ipykernel_58406/795959617.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:,'percentage'] = y_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disToRiv</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TPI</th>\n",
       "      <th>FAcc</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419089</th>\n",
       "      <td>393.85910</td>\n",
       "      <td>10.20537</td>\n",
       "      <td>0.54161</td>\n",
       "      <td>27.04812</td>\n",
       "      <td>4.70770</td>\n",
       "      <td>152.60564</td>\n",
       "      <td>367648</td>\n",
       "      <td>5261043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388753</th>\n",
       "      <td>102.59142</td>\n",
       "      <td>16.06245</td>\n",
       "      <td>-0.05203</td>\n",
       "      <td>9458.78809</td>\n",
       "      <td>1.66023</td>\n",
       "      <td>197.74588</td>\n",
       "      <td>362193</td>\n",
       "      <td>5261148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494166</th>\n",
       "      <td>110.00000</td>\n",
       "      <td>13.18089</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>530.13470</td>\n",
       "      <td>1.49737</td>\n",
       "      <td>144.01004</td>\n",
       "      <td>361608</td>\n",
       "      <td>5266063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61008</th>\n",
       "      <td>136.01471</td>\n",
       "      <td>10.95948</td>\n",
       "      <td>0.01625</td>\n",
       "      <td>57.49655</td>\n",
       "      <td>8.96356</td>\n",
       "      <td>169.10132</td>\n",
       "      <td>362008</td>\n",
       "      <td>5267198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203168</th>\n",
       "      <td>90.13878</td>\n",
       "      <td>2.90234</td>\n",
       "      <td>-0.04885</td>\n",
       "      <td>53.52814</td>\n",
       "      <td>4.69841</td>\n",
       "      <td>85.86313</td>\n",
       "      <td>366483</td>\n",
       "      <td>5264443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          disToRiv       TWI      TPI        FAcc    slope  elevation  \\\n",
       "2419089  393.85910  10.20537  0.54161    27.04812  4.70770  152.60564   \n",
       "2388753  102.59142  16.06245 -0.05203  9458.78809  1.66023  197.74588   \n",
       "494166   110.00000  13.18089  0.00468   530.13470  1.49737  144.01004   \n",
       "61008    136.01471  10.95948  0.01625    57.49655  8.96356  169.10132   \n",
       "1203168   90.13878   2.90234 -0.04885    53.52814  4.69841   85.86313   \n",
       "\n",
       "         x_coord  y_coord  percentage  \n",
       "2419089   367648  5261043           0  \n",
       "2388753   362193  5261148           0  \n",
       "494166    361608  5266063           0  \n",
       "61008     362008  5267198           0  \n",
       "1203168   366483  5264443           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####    Creating training set     #####\n",
    "X_train.loc[:,'percentage'] = y_train\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/cqkwnnps0f1_35_bccj0y8q80000gn/T/ipykernel_58406/1019043263.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.drop(['x_coord','y_coord'], axis =1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disToRiv</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TPI</th>\n",
       "      <th>FAcc</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419089</th>\n",
       "      <td>393.85910</td>\n",
       "      <td>10.20537</td>\n",
       "      <td>0.54161</td>\n",
       "      <td>27.04812</td>\n",
       "      <td>4.70770</td>\n",
       "      <td>152.60564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388753</th>\n",
       "      <td>102.59142</td>\n",
       "      <td>16.06245</td>\n",
       "      <td>-0.05203</td>\n",
       "      <td>9458.78809</td>\n",
       "      <td>1.66023</td>\n",
       "      <td>197.74588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494166</th>\n",
       "      <td>110.00000</td>\n",
       "      <td>13.18089</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>530.13470</td>\n",
       "      <td>1.49737</td>\n",
       "      <td>144.01004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61008</th>\n",
       "      <td>136.01471</td>\n",
       "      <td>10.95948</td>\n",
       "      <td>0.01625</td>\n",
       "      <td>57.49655</td>\n",
       "      <td>8.96356</td>\n",
       "      <td>169.10132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203168</th>\n",
       "      <td>90.13878</td>\n",
       "      <td>2.90234</td>\n",
       "      <td>-0.04885</td>\n",
       "      <td>53.52814</td>\n",
       "      <td>4.69841</td>\n",
       "      <td>85.86313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          disToRiv       TWI      TPI        FAcc    slope  elevation  \\\n",
       "2419089  393.85910  10.20537  0.54161    27.04812  4.70770  152.60564   \n",
       "2388753  102.59142  16.06245 -0.05203  9458.78809  1.66023  197.74588   \n",
       "494166   110.00000  13.18089  0.00468   530.13470  1.49737  144.01004   \n",
       "61008    136.01471  10.95948  0.01625    57.49655  8.96356  169.10132   \n",
       "1203168   90.13878   2.90234 -0.04885    53.52814  4.69841   85.86313   \n",
       "\n",
       "         percentage  \n",
       "2419089           0  \n",
       "2388753           0  \n",
       "494166            0  \n",
       "61008             0  \n",
       "1203168           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removing coordinates from training set\n",
    "X_train.drop(['x_coord','y_coord'], axis =1, inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('datasets/basin1_FirstFeatureSet_Clean_Training.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          disToRiv       TWI      TPI        FAcc     slope  elevation  \\\n",
      "1149772   65.76473  15.88676  0.10242  7934.72021   5.60282  108.43757   \n",
      "1110309  579.82758   9.04799  0.01117  1758.07971   1.66141  165.68309   \n",
      "98254     65.19202   1.79303  0.54303    64.37885  13.80903  142.59601   \n",
      "242062   215.92822  13.59605 -0.12878   802.94952   1.87882  166.73584   \n",
      "1093319  166.17009   3.08946  0.01888   275.23352   5.40569  170.24129   \n",
      "\n",
      "         x_coord  y_coord  \n",
      "1149772   364493  5264573  \n",
      "1110309   369238  5264668  \n",
      "98254     371563  5267053  \n",
      "242062    362363  5266648  \n",
      "1093319   360698  5264703  \n",
      "          disToRiv       TWI      TPI        FAcc     slope  elevation  \\\n",
      "1149772   65.76473  15.88676  0.10242  7934.72021   5.60282  108.43757   \n",
      "1110309  579.82758   9.04799  0.01117  1758.07971   1.66141  165.68309   \n",
      "98254     65.19202   1.79303  0.54303    64.37885  13.80903  142.59601   \n",
      "242062   215.92822  13.59605 -0.12878   802.94952   1.87882  166.73584   \n",
      "1093319  166.17009   3.08946  0.01888   275.23352   5.40569  170.24129   \n",
      "\n",
      "         x_coord  y_coord  percentage  \n",
      "1149772   364493  5264573           0  \n",
      "1110309   369238  5264668           0  \n",
      "98254     371563  5267053           0  \n",
      "242062    362363  5266648           0  \n",
      "1093319   360698  5264703           0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 495908 entries, 1149772 to 124321\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   disToRiv    495908 non-null  float64\n",
      " 1   TWI         495908 non-null  float64\n",
      " 2   TPI         495908 non-null  float64\n",
      " 3   FAcc        495908 non-null  float64\n",
      " 4   slope       495908 non-null  float64\n",
      " 5   elevation   495908 non-null  float64\n",
      " 6   x_coord     495908 non-null  int64  \n",
      " 7   y_coord     495908 non-null  int64  \n",
      " 8   percentage  495908 non-null  int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 37.8 MB\n",
      "None\n",
      "testCount:  Counter({0: 485332, 5: 8764, 1: 1812})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/cqkwnnps0f1_35_bccj0y8q80000gn/T/ipykernel_58406/345470071.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.loc[:,'percentage'] = y_test\n"
     ]
    }
   ],
   "source": [
    "#####. Creating Test set\n",
    "print(X_test.head())\n",
    "X_test.loc[:,'percentage'] = y_test\n",
    "print(X_test.head())\n",
    "print(X_test.info())\n",
    "testCount = Counter(X_test['percentage'])\n",
    "print(f\"testCount:  {testCount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('datasets/basin1_FirstFeatureSet_Clean_Test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Train samples: 1983630,  total Validation samples: 495908\n",
      "Summary of traning and test dataset class balance\n",
      "Training Set: \n",
      " Class 0: 0.979  Class 1: 0.0037 Class 5: 0.0177\n",
      "Testing Set: \n",
      " Class 0: 0.979  Class 1: 0.0037 Class 5: 0.0177\n"
     ]
    }
   ],
   "source": [
    "## This proportions are the reason why a sample_weight of 0.01 for the majority class give best results for regression\n",
    "totalTrain = sum([trainCount[0], trainCount[1], trainCount[5]]) \n",
    "totalValidation = sum([testCount[0], testCount[1], testCount[5]])\n",
    "print(f\"total Train samples: {totalTrain},  total Validation samples: {totalValidation}\")\n",
    "print(\"Summary of traning and test dataset class balance\")\n",
    "print(f\"Training Set:\", '\\n', \"Class 0: %.3f\" %(trainCount[0]/totalTrain), \" Class 1: %.4f\" %(trainCount[1]/totalTrain), \"Class 5: %.4f\"%(trainCount[5]/totalTrain))\n",
    "print(\"Testing Set:\", '\\n', \"Class 0: %.3f\" %(testCount[0]/totalValidation),\" Class 1: %.4f\" %(testCount[1]/totalValidation),  \"Class 5: %.4f\"%(testCount[5]/totalValidation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ms.loadModel('./outputs/2022-08-05/00-35-58/2208050035.pkl')\n",
    "dataSetToSave = ms.makePredictionToImportAsSHP(csvName, model, X, Y, 'percentage')\n",
    "print(dataSetToSave.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining dataSets to build AllVsOne_training and OneVsAll_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat datasets\n",
    "sourceFileForDatasets = 'datasets/'\n",
    "allDataSetsNames = ['basin1Light_Clean.csv', 'basin2_CleanDataSet.csv', 'basin3_CleanDataSet_copy.csv','basin4_CleanDataSet.csv','basin5_CleanDataSet.csv']\n",
    "# OneVsAllDataSetName = 'basin1Light_Clean.csv'\n",
    "\n",
    "for datasetForTest in allDataSetsNames:\n",
    "    filename, file_extension = os.path.splitext(datasetForTest)\n",
    "    newListOfNames = [s for s in allDataSetsNames if s != datasetForTest]\n",
    "    allDataSetsFileName = 'allVs_'+ filename +'_Training'\n",
    "    DFToConcatAll = pd.DataFrame()\n",
    "#     DFToConcatAll = pd.read_csv((sourceFileForDatasets+datasetForTest), index_col = None)\n",
    "#     print(DFToConcatAll.head())\n",
    "    for datasets in newListOfNames:\n",
    "        DFToConcatAll = pd.concat([DFToConcatAll, pd.read_csv((sourceFileForDatasets+datasets), index_col = None)])\n",
    "    nameToSafe = sourceFileForDatasets+allDataSetsFileName+file_extension\n",
    "    DFToConcatAll.drop(['x_coord','y_coord'], axis =1, inplace=True)\n",
    "    DFToConcatAll.to_csv(nameToSafe, index=None)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controled sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv('datasets/basin2 _Training.csv', index_col = None)\n",
    "print(DS.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DS.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(DS['FAProx_01']) # , , DS['elevation'], DS['disToRiv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resampling appliying class selection by rule:\n",
    "\n",
    "# RULE1: Select point at a distance to river less than 300m. \n",
    "\n",
    "# # newDS = pseudoClassCreation(DS, \"distanceToRiver\", 300, 2)\n",
    "def pseudoClassCreation(dataset, conditionVariable, threshold, pseudoClass, targetClassName):\n",
    "    '''\n",
    "    Replace <targetClass> by  <pseudoClass> where <conditionVariable >= threshold>. \n",
    "    Return:\n",
    "      dataset with new classes group. \n",
    "    '''\n",
    "    datsetReclassified = dataset.copy()\n",
    "    actualTarget = (np.array(dataset[targetClassName])).ravel()\n",
    "    conditionVar = (np.array(dataset[conditionVariable])).ravel()\n",
    "    datsetReclassified[targetClassName] = [ pseudoClass if conditionVar[j] >= threshold \n",
    "                                           else actualTarget[j]\n",
    "                                           for j in range(len(actualTarget))]\n",
    "    print(Counter(datsetReclassified[targetClassName]))\n",
    "    return  datsetReclassified\n",
    "\n",
    "def revertPseudoClassCreation(dataset, originalClass, pseudoClass, targetClassName):\n",
    "    '''\n",
    "    Restablich  <targetClass> with <originalClass> where <targetClassName == pseudoClass>. \n",
    "    Return:\n",
    "      dataset with original classes group. \n",
    "    '''\n",
    "    datsetReclassified = dataset.copy()\n",
    "    actualTarget = (np.array(dataset[targetClassName])).ravel()\n",
    "    datsetReclassified[targetClassName] = [ originalClass if actualTarget[j] == pseudoClass\n",
    "                                           else actualTarget[j]\n",
    "                                           for j in range(len(actualTarget))]\n",
    "    print(Counter(datsetReclassified[targetClassName]))\n",
    "    return  datsetReclassified\n",
    "\n",
    "\n",
    "print(Counter(X_train['percentage']))\n",
    "newDS = pseudoClassCreation(X_train, 'disToRiv', 200, 2, 'percentage')\n",
    "y = newDS['percentage']\n",
    "newDS.drop(['percentage'], axis=1, inplace = True)\n",
    "x_res,y_res = ms.randomUndersampling(newDS, y, )\n",
    "x_res['percentage'] = y_res\n",
    "# newDatase = revertPseudoClassCreation(x_res, 0, 2, 'percentage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res.to_csv('basin1ControlClass0Sampling4Class_ToSHP.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import dataset to describe\n",
    "DS= pd.read_csv('datasets/basin4_Training.csv', index_col=None)\n",
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.drop(['x_coord','y_coord'], axis = 1, inplace=True)\n",
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAcc vs Labels\n",
    "targets = DS['percentage']\n",
    "FAcc = original['FAcc']\n",
    "FAcc_norm = DS['FAcc_norm']\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13,4), sharey=True)\n",
    "fig.text(-0.02, 0.5, 'labels', va='center', rotation='vertical')\n",
    "fig.text(0.5, 1, 'Flow accumulation vs labels distribution', ha ='center')\n",
    "axs[0].scatter(FAcc,targets)\n",
    "# axs[0].set_title(\"Facc\")\n",
    "axs[0].set(xlabel='a) Flow Accumulation')\n",
    "axs[1].scatter(FAcc_norm,targets)\n",
    "# axs[1].set_title(\"FAcc_norm\")\n",
    "axs[1].set(xlabel='b) Flow Accumulation estandardized')\n",
    "plt.rcParams['font.size'] = '20'\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Plot all features vs labels\n",
    "# 'disToRiv', 'TWI', 'TPI', 'slope', 'elevation',\n",
    "\n",
    "targets = DS['percentage']\n",
    "# targets = np.where(targets == 5,2,targets)\n",
    "\n",
    "E = DS['elevation'] \n",
    "slope = DS['slope']\n",
    "FAcc = DS['FAcc']\n",
    "TWI = DS['TWI']\n",
    "TPI = DS['TPI']\n",
    "DLSOL4R150 = DS['LDSOL4R150']\n",
    "DLSOL5R150 = DS['LDSOL5R150']\n",
    "DLSOL5R200 = DS['LDSOL5R200']\n",
    "FAProx_01 = DS['FAProx_01']\n",
    "FAProx_025 = DS['FAProx_025']\n",
    "visibility = DS['visibility']\n",
    "\n",
    "fig, axs = plt.subplots(4,3, figsize=(13, 8), sharey=True)\n",
    "fig.supylabel('Labels')\n",
    "plt.rcParams['font.size'] = '15'\n",
    "plt.yticks([0,1,5])\n",
    "\n",
    "'''\n",
    "E = DS['elevation'] \n",
    "slope = DS['slope']\n",
    "FAcc = DS['FAcc']\n",
    "TWI = DS['TWI']\n",
    "'''\n",
    "axs[0, 0].scatter(E,targets)\n",
    "axs[0, 0].set_title(\"Elevation\")\n",
    "axs[1, 0].scatter(slope,targets)\n",
    "axs[1, 0].set_title(\"Slope\")\n",
    "axs[2, 0].scatter(FAcc,targets)\n",
    "axs[2, 0].set_title(\"Flow accumulation\")\n",
    "axs[3, 0].scatter(TWI,targets)\n",
    "axs[3, 0].set_title(\"TWI\")\n",
    "\n",
    "'''\n",
    "TPI = DS['TPI']\n",
    "DLSOL4R150 = DS['DLSOL4R150']\n",
    "DLSOL5R150 = DS['DLSOL5R150']\n",
    "DLSOL5R200 = DS['DLSOL5R200']\n",
    "'''\n",
    "axs[0, 1].scatter(TPI,targets)\n",
    "axs[0, 1].set_title('TPI')\n",
    "axs[1, 1].scatter(DLSOL4R150,targets)\n",
    "axs[1, 1].set_title(\"DLSOL4R150\")\n",
    "axs[2, 1].scatter(DLSOL5R150,targets)\n",
    "axs[2, 1].set_title(\"DLSOL5R150\")\n",
    "axs[3, 1].scatter(DLSOL5R200,targets)\n",
    "axs[3, 1].set_title(\"DLSOL5R200\")\n",
    "\n",
    "'''\n",
    "FAProx_01 = DS['FAProx_01']\n",
    "FAProx_025 = DS['FAProx_025']\n",
    "visibility = DS['visibility']\n",
    "'''\n",
    "axs[0, 2].scatter(FAProx_01,targets)\n",
    "axs[0, 2].set_title('FAProx_01')\n",
    "axs[1, 2].scatter(FAProx_025,targets)\n",
    "axs[1, 2].set_title(\"FAProx_025\")\n",
    "axs[2, 2].scatter(visibility,targets)\n",
    "axs[2, 2].set_title(\"Visibility\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DS.head())\n",
    "#  Return a dataset with the rows corresponding to the index where condition in DS.columName is valid. \n",
    "dsArray = DS[DS.percentage != 0] \n",
    "print(dsArray.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.pairplot(DS, hue = 'percentage', diag_kind = 'kde', \n",
    "             plot_kws = {'alpha': 0.8, 's': 100},\n",
    "             height = 4, corner=True, palette = \"Set2\")# vars = ['life_exp', 'log_pop', 'log_gdp_per_cap'],\n",
    "\n",
    "# sns.pairplot(DS, hue=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Covariance Matrix\n",
    "sns.set(font_scale=0.7)\n",
    "matrix = DS.corr().round(2)\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.set_figsize=(25,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(criterion='entropy', random_state = 50)\n",
    "x_train,y_train = ms.importDataSet('basin1Train.csv', 'percentage')\n",
    "classifier = OneVsRestClassifier(estimator).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ms.loadModel('./outputs/2022-08-05/11-01-57/2208051101.pkl')\n",
    "x_test,y_test = ms.importDataSet('basin1Test.csv', 'percentage')\n",
    "\n",
    "x_test = ms.removeCoordinatesFromDataSet(x_test)\n",
    "\n",
    "# y_prob = classifier.predict_proba(x_test)\n",
    "#print(np.unique(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.plot_ROC_AUC_OneVsRest(classifier, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,y_test = ms.importDataSet('./bestModels/Classifier/10-18-08/2208051018prediction_basin1Test.csv', 'prediction')\n",
    "unique, count = np.unique(y_test, return_counts=True)\n",
    "total = count.sum()\n",
    "print(total)\n",
    "percent = np.round(np.zeros_like(unique).astype('float16'),3)\n",
    "print('values, counts , percent')\n",
    "for i in range(len(unique)):    \n",
    "   percent[i] = (count[i]/total)*100\n",
    "   print(unique[i],\"\\t\", count[i], percent[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c444c068df4da933f83035bc75b2ed5aea8e7fb8bc113357e2f14ee7cca6a8fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
