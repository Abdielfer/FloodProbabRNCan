{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import myServices as ms\n",
    "import randForest as rfr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, roc_auc_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute ececution time do:\n",
    "# with timeit():\n",
    "#     # your code, e.g., \n",
    "class timeit(): \n",
    "    from datetime import datetime\n",
    "    def __enter__(self):\n",
    "        self.tic = self.datetime.now()\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print('runtime: {}'.format(self.datetime.now() - self.tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and manipulating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBasin1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin1CleanToTrain.csv\n",
    "# original = pd.read_csv('basin1CleanToTrain.csv', index_col = None)\n",
    "DS = pd.read_csv('datasetBasin1.csv', index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>disToRiv</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TPI</th>\n",
       "      <th>FAcc</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493979e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.479538e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "      <td>2.493980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.150033e-02</td>\n",
       "      <td>2.097987e+02</td>\n",
       "      <td>9.478135e+00</td>\n",
       "      <td>1.100693e-04</td>\n",
       "      <td>4.330615e+04</td>\n",
       "      <td>4.821367e+00</td>\n",
       "      <td>1.455343e+02</td>\n",
       "      <td>3.650845e+05</td>\n",
       "      <td>5.264240e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.592287e-01</td>\n",
       "      <td>1.727702e+02</td>\n",
       "      <td>4.079174e+00</td>\n",
       "      <td>1.950585e-01</td>\n",
       "      <td>1.029387e+06</td>\n",
       "      <td>4.994698e+00</td>\n",
       "      <td>4.576501e+01</td>\n",
       "      <td>3.175800e+03</td>\n",
       "      <td>1.830620e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.252120e+00</td>\n",
       "      <td>-7.461320e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>4.700000e-04</td>\n",
       "      <td>-3.808000e-02</td>\n",
       "      <td>3.586730e+05</td>\n",
       "      <td>5.260213e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.424622e+01</td>\n",
       "      <td>5.551585e+00</td>\n",
       "      <td>-6.195000e-02</td>\n",
       "      <td>8.772391e+01</td>\n",
       "      <td>1.600760e+00</td>\n",
       "      <td>1.159088e+02</td>\n",
       "      <td>3.623130e+05</td>\n",
       "      <td>5.262718e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.691892e+02</td>\n",
       "      <td>1.025464e+01</td>\n",
       "      <td>-2.100000e-04</td>\n",
       "      <td>2.851745e+02</td>\n",
       "      <td>3.192175e+00</td>\n",
       "      <td>1.483494e+02</td>\n",
       "      <td>3.650780e+05</td>\n",
       "      <td>5.264348e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.030264e+02</td>\n",
       "      <td>1.288554e+01</td>\n",
       "      <td>6.131000e-02</td>\n",
       "      <td>1.254889e+03</td>\n",
       "      <td>6.192805e+00</td>\n",
       "      <td>1.800543e+02</td>\n",
       "      <td>3.676380e+05</td>\n",
       "      <td>5.265788e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.355775e+03</td>\n",
       "      <td>2.486353e+01</td>\n",
       "      <td>6.706970e+00</td>\n",
       "      <td>6.282632e+07</td>\n",
       "      <td>7.002943e+01</td>\n",
       "      <td>2.605691e+02</td>\n",
       "      <td>3.721230e+05</td>\n",
       "      <td>5.267983e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         percentage      disToRiv           TWI           TPI          FAcc  \\\n",
       "count  2.493980e+06  2.493980e+06  2.493979e+06  2.493980e+06  2.493980e+06   \n",
       "mean   9.150033e-02  2.097987e+02  9.478135e+00  1.100693e-04  4.330615e+04   \n",
       "std    6.592287e-01  1.727702e+02  4.079174e+00  1.950585e-01  1.029387e+06   \n",
       "min    0.000000e+00  0.000000e+00 -9.252120e+00 -7.461320e+00  2.500000e+01   \n",
       "25%    0.000000e+00  7.424622e+01  5.551585e+00 -6.195000e-02  8.772391e+01   \n",
       "50%    0.000000e+00  1.691892e+02  1.025464e+01 -2.100000e-04  2.851745e+02   \n",
       "75%    0.000000e+00  3.030264e+02  1.288554e+01  6.131000e-02  1.254889e+03   \n",
       "max    5.000000e+00  1.355775e+03  2.486353e+01  6.706970e+00  6.282632e+07   \n",
       "\n",
       "              slope     elevation       x_coord       y_coord  \n",
       "count  2.479538e+06  2.493980e+06  2.493980e+06  2.493980e+06  \n",
       "mean   4.821367e+00  1.455343e+02  3.650845e+05  5.264240e+06  \n",
       "std    4.994698e+00  4.576501e+01  3.175800e+03  1.830620e+03  \n",
       "min    4.700000e-04 -3.808000e-02  3.586730e+05  5.260213e+06  \n",
       "25%    1.600760e+00  1.159088e+02  3.623130e+05  5.262718e+06  \n",
       "50%    3.192175e+00  1.483494e+02  3.650780e+05  5.264348e+06  \n",
       "75%    6.192805e+00  1.800543e+02  3.676380e+05  5.265788e+06  \n",
       "max    7.002943e+01  2.605691e+02  3.721230e+05  5.267983e+06  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balanced sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1995184 TEST: [ 756851  359082 1003874 ... 1000311 1257022 1105391]\n"
     ]
    }
   ],
   "source": [
    "## Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X,Y = ms.importDataSet('datasetBasin1.csv', 'percentage')\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=50)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index.size, \"TEST:\", test_index)\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = Y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = Y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1952867\n",
      "5      35061\n",
      "1       7256\n",
      "Name: percentage, dtype: int64\n",
      "0    488217\n",
      "5      8765\n",
      "1      1814\n",
      "Name: percentage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print( y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance summary of train dataset\n",
      "Class 1% : 0.9787904273490565, Class 1%: 0.003636757311606348, Class 5%: 0.017572815339337123\n",
      "Class 1% : 0.9787909285559627, Class 1%: 0.003636757311606348, Class 5%: 0.017572314132430895\n"
     ]
    }
   ],
   "source": [
    "## This proportions ar\n",
    "\n",
    "totalTrain = sum([1952867, 35061,7256])\n",
    "totalValidation = sum([488217,8765,1814])\n",
    "print(\"Balance summary of train dataset\")\n",
    "print(f\"Class 1% : {1952867/totalTrain}, Class 1%: {7256/totalTrain}, Class 5%: {35061/totalTrain}\")\n",
    "print(f\"Class 1% : {488217/totalValidation}, Class 1%: {1814/totalValidation}, Class 5%: {8765/totalValidation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = ms.importDataSet('basin1_FaccNorm.csv', 'percentage')\n",
    "x_train,x_validation,y_train, y_validation = train_test_split(X,Y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation['percentage'] = y_validation\n",
    "print(x_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation.to_csv('basin1Validation.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['percentage'] = y_train\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('basin1Train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFClassifier = rfr.implementRandomForestCalssifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rfr.loadModel('./bestModels/21-46-40 Classifier/2207232146.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAcc vs Labels\n",
    "targets = DS['percentage']\n",
    "FAcc = original['FAcc']\n",
    "FAcc_norm = DS['FAcc_norm']\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13,4), sharey=True)\n",
    "fig.text(-0.02, 0.5, 'labels', va='center', rotation='vertical')\n",
    "fig.text(0.5, 1, 'Flow accumulation vs labels distribution', ha ='center')\n",
    "axs[0].scatter(FAcc,targets)\n",
    "# axs[0].set_title(\"Facc\")\n",
    "axs[0].set(xlabel='a) Flow Accumulation')\n",
    "axs[1].scatter(FAcc_norm,targets)\n",
    "# axs[1].set_title(\"FAcc_norm\")\n",
    "axs[1].set(xlabel='b) Flow Accumulation estandardized')\n",
    "plt.rcParams['font.size'] = '20'\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##3 Al features vs labels\n",
    "# 'disToRiv', 'TWI', 'TPI', 'slope', 'elevation',\n",
    "targets = DS['percentage']\n",
    "# targets = np.where( targets == 5, 2,targets)\n",
    "\n",
    "E = DS['elevation'] \n",
    "slope = DS['slope']\n",
    "FAcc = DS['FAcc_norm']\n",
    "S = DS['disToRiv']\n",
    "TWI = DS['TWI']\n",
    "TPI = DS['TPI']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(13, 8), sharey=True)\n",
    "fig.supylabel('Labels')\n",
    "plt.rcParams['font.size'] = '15'\n",
    "plt.yticks([0,1,5])\n",
    "axs[0, 0].scatter(E,targets)\n",
    "axs[0, 0].set_title(\"Elevation\")\n",
    "axs[1, 0].scatter(slope,targets)\n",
    "axs[1, 0].set_title(\"Slope\")\n",
    "axs[2, 0].scatter(FAcc,targets)\n",
    "axs[2, 0].set_title(\"Flow accumulation\")\n",
    "axs[0, 1].scatter(S,targets)\n",
    "axs[0, 1].set_title(\"Distance to river\")\n",
    "axs[1, 1].scatter(TWI,targets)\n",
    "axs[1, 1].set_title(\"TWI\")\n",
    "axs[2, 1].scatter(TPI,targets)\n",
    "axs[2, 1].set_title('TPI')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DS.head())\n",
    "#  Return a dataset with the rows corresponding to the index where condition in DS.columName is valid. \n",
    "dsArray = DS[DS.percentage != 0] print(dsArray.head())\n",
    "print(dsArray.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.pairplot(DS, hue = 'percentage', diag_kind = 'kde', \n",
    "             plot_kws = {'alpha': 0.8, 's': 100},\n",
    "             height = 4, corner=True, palette = \"Set2\")# vars = ['life_exp', 'log_pop', 'log_gdp_per_cap'],\n",
    "\n",
    "# sns.pairplot(DS, hue=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Covariance Matrix\n",
    "matrix = DS.corr().round(2)\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(criterion='entropy', random_state = 50)\n",
    "x_train,y_train = ms.importDataSet('basin1Train.csv', 'percentage')\n",
    "classifier = OneVsRestClassifier(estimator).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = rfr.loadModel('./outputs/2022-08-02/11-01-47/2208021101.pkl')\n",
    "x_test,y_test = ms.importDataSet('basin1Validation.csv', 'percentage')\n",
    "y_prob = classifier.predict_proba(x_test)\n",
    "#print(np.unique(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.plot_ROC_AUC_OneVsRest(classifier, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c444c068df4da933f83035bc75b2ed5aea8e7fb8bc113357e2f14ee7cca6a8fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
