### config/parameters/param.yaml  
epochs : 300
testSize : 0.2
batchSize : 100
random_state: 50
hidden_layer_sizes: []
early_stopping: True
verbose: False
modelsFolder : C:\Users\abfernan\CrossCanFloodMapping\FloodMappingProjData\HRDTMByAOI\MLP_Models\
colsToDrop : ['x_coord','y_coord','Aoi_Id','FloodOrd','d8fllowAcc']

### Training configuration
init_weight:
 _partial_: True 
 _target_: torch.nn.init.normal_
# torch.nn.init.kaiming_normal_  -->> initWeightParams: {mode:'fan_out', nonlinearity :'leaky_relu'} #Options : nonlinearity :'leaky_relu' or 'relu' 
  # torch.nn.init.normal_  -->> initWeightParams:{mean:0.0, std : 0.01}
initWeightParams: [0.0,0.01] # {mean: 0.0, std : 0.01} 

model:
  _partial_: True 
  _target_: models.MLP_6

criterion:
  _partial_: True 
  _target_: torch.nn.BCELoss
  reduction : 'mean'

optimizer:
  _partial_: True 
  _target_: torch.optim.Adam
  maximize : False
  lr: 0.00025
  #weight_decay : 0.1

scheduler:
 _partial_: True 
 _target_ : torch.optim.lr_scheduler.ReduceLROnPlateau
 mode : min
 patience : 10
 factor : 0.80
 threshold : 0.001

# scheduler = lr_scheduler.LinearLR(optimizer,start_factor: 1.0, end_factor : 0.3, total_iters : 10)
# scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)

kFold: False
n_folds : 5
