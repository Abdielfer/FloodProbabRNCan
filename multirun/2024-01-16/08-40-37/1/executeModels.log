[2024-01-16 09:21:36,598][executeModels][INFO] - model name - 2401160921
[2024-01-16 09:21:36,598][executeModels][INFO] - model - {'_partial_': True, '_target_': 'models.MLP_6'}
[2024-01-16 09:21:36,598][executeModels][INFO] - loss function - {'_partial_': True, '_target_': 'torch.nn.BCELoss', 'reduction': 'mean'}
[2024-01-16 09:21:36,598][executeModels][INFO] - optimizer - {'_partial_': True, '_target_': 'torch.optim.Adam', 'maximize': False, 'lr': 0.01}
[2024-01-16 09:21:36,598][executeModels][INFO] - schedule - {'_partial_': True, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'patience': 10, 'factor': 0.85, 'threshold': 0.001}
[2024-01-16 09:21:36,613][executeModels][INFO] - Cols To Drop - ['x_coord', 'y_coord']
[2024-01-16 09:21:36,613][executeModels][INFO] - Data Set - C:\Users\abfernan\CrossCanFloodMapping\FloodMappingProjData\HRDTMByAOI\A_DatasetsForMLP\RegionalModelingExplorationDatasets\TrainingDataset_RastComb_Normalized_class5.csv
[2024-01-16 09:21:36,698][executeModels][INFO] - Epochs - 150
[2024-01-16 09:21:36,698][executeModels][INFO] - Batch Size - 100
[2024-01-16 09:21:36,698][executeModels][INFO] - training Mode - Single train
[2024-01-16 09:21:36,963][executeModels][INFO] - Testing on Validation Dataset - C:\Users\abfernan\CrossCanFloodMapping\FloodMappingProjData\HRDTMByAOI\A_DatasetsForMLP\RegionalModelingExplorationDatasets\ValidationSet_RastComb_Normalized_class5.csv
[2024-01-16 09:50:54,046][executeModels][INFO] - Last train metric - {'accScore': 0.9204793458617659, 'macro_averaged_f1': 0.7435342217840073, 'micro_averaged_f1': 0.9204793458617659}
[2024-01-16 09:50:54,047][executeModels][INFO] - model Name - 2401160921.pkl
[2024-01-16 09:50:54,047][executeModels][INFO] - Test metric - {'accScore': 0.9204793458617659, 'macro_averaged_f1': 0.7435342217840073, 'micro_averaged_f1': 0.9204793458617659}
[2024-01-16 09:50:55,025][executeModels][INFO] - Validation metric - {'accScore': 0.9204793458617659, 'macro_averaged_f1': 0.7435342217840073, 'micro_averaged_f1': 0.9204793458617659}
